[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Deep Learning",
    "section": "",
    "text": "Professor Kwangsoo Kim, Department of Statistics, Jeonbuk National University\n2nd semester, 2023\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nNov 27, 2023\n\n\n[DL] VAE\n\n\n김보람 \n\n\n\n\nNov 13, 2023\n\n\n[DL] CV_CIFAR(1)\n\n\n김보람 \n\n\n\n\nNov 13, 2023\n\n\n[DL] Att01\n\n\n김보람 \n\n\n\n\nOct 30, 2023\n\n\n[ADL] Take Home\n\n\n김보람 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/[ADL] HW1.html",
    "href": "posts/[ADL] HW1.html",
    "title": "[ADL] Take Home",
    "section": "",
    "text": "해당 강의노트는 전북대학교 김광수교수님 2023-2 고급딥러닝 자료임\n제출기한~11/10"
  },
  {
    "objectID": "posts/[ADL] HW1.html#a",
    "href": "posts/[ADL] HW1.html#a",
    "title": "[ADL] Take Home",
    "section": "(a)",
    "text": "(a)\nCalculate \\(\\dfrac{∂ℓ}{∂w^{(l)}_{kj}}\\) for \\((l, k, j) ∈ \\{4, 1\\} × \\{1 \\} × \\{1, 2\\}\\)"
  },
  {
    "objectID": "posts/[ADL] HW1.html#b",
    "href": "posts/[ADL] HW1.html#b",
    "title": "[ADL] Take Home",
    "section": "(b)",
    "text": "(b)\nAssume that we have two mini-batches such that \\(\\{x = (2, 3), y = 6\\}\\) and \\(\\{x = (1, 4), y = 7\\}\\), and \\(ℓ = (y − f)^2\\) . Also, we initialize all values of \\(w^{(l)}_{kj} , w_j , b^{(l)}\\) and \\(b\\) as \\(1/10\\). Consider the updating rule of \\(w_{t+1} = w_t − ϵ∇_wℓ_t\\)."
  },
  {
    "objectID": "posts/[ADL] HW1.html#c",
    "href": "posts/[ADL] HW1.html#c",
    "title": "[ADL] Take Home",
    "section": "(c)",
    "text": "(c)\nCalculate the updated value of \\(w^{(2)}_{1,2}\\) at the first step only using the first batch."
  },
  {
    "objectID": "posts/Att01.html",
    "href": "posts/Att01.html",
    "title": "[DL] Att01",
    "section": "",
    "text": "해당 강의노트는 전북대학교 김광수교수님 2023-2 고급딥러닝 자료임\n\n\n## https://www.tensorflow.org/tutorials/keras/regression?hl=ko ##\n\nimport pathlib\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nprint(tf.__version__)\n\n2.14.0\n\n\n\ndataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\ndataset_path\n\n'/root/.keras/datasets/auto-mpg.data'\n\n\n\ncolumn_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n                'Acceleration', 'Model Year', 'Origin']\nraw_dataset = pd.read_csv(dataset_path, names=column_names,\n                      na_values = \"?\", comment='\\t',\n                      sep=\" \", skipinitialspace=True)\n\ndataset = raw_dataset.copy()\ndataset.tail()\n\n\n  \n    \n\n\n\n\n\n\nMPG\nCylinders\nDisplacement\nHorsepower\nWeight\nAcceleration\nModel Year\nOrigin\n\n\n\n\n393\n27.0\n4\n140.0\n86.0\n2790.0\n15.6\n82\n1\n\n\n394\n44.0\n4\n97.0\n52.0\n2130.0\n24.6\n82\n2\n\n\n395\n32.0\n4\n135.0\n84.0\n2295.0\n11.6\n82\n1\n\n\n396\n28.0\n4\n120.0\n79.0\n2625.0\n18.6\n82\n1\n\n\n397\n31.0\n4\n119.0\n82.0\n2720.0\n19.4\n82\n1\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\ndataset = dataset.dropna()\norigin = dataset.pop('Origin')\n#dataset['USA'] = (origin == 1)*1.0\ndataset['Europe'] = (origin == 2)*1.0\ndataset['Japan'] = (origin == 3)*1.0\ndataset.tail()\n\nSettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  dataset['USA'] = (origin == 1)*1.0\n&lt;ipython-input-5-f05403a9f198&gt;:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  dataset['Europe'] = (origin == 2)*1.0\n&lt;ipython-input-5-f05403a9f198&gt;:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  dataset['Japan'] = (origin == 3)*1.0\n\n\n\n  \n    \n\n\n\n\n\n\nMPG\nCylinders\nDisplacement\nHorsepower\nWeight\nAcceleration\nModel Year\nUSA\nEurope\nJapan\n\n\n\n\n393\n27.0\n4\n140.0\n86.0\n2790.0\n15.6\n82\n1.0\n0.0\n0.0\n\n\n394\n44.0\n4\n97.0\n52.0\n2130.0\n24.6\n82\n0.0\n1.0\n0.0\n\n\n395\n32.0\n4\n135.0\n84.0\n2295.0\n11.6\n82\n1.0\n0.0\n0.0\n\n\n396\n28.0\n4\n120.0\n79.0\n2625.0\n18.6\n82\n1.0\n0.0\n0.0\n\n\n397\n31.0\n4\n119.0\n82.0\n2720.0\n19.4\n82\n1.0\n0.0\n0.0\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\ntrain_dataset = dataset.sample(frac=0.8,random_state=0)\ntest_dataset = dataset.drop(train_dataset.index)\ntrain_stats = train_dataset.describe()\ntrain_stats.pop(\"MPG\")\ntrain_stats = train_stats.transpose()\ntrain_stats\n\n\ntrain_labels = train_dataset.pop('MPG')\ntest_labels = test_dataset.pop('MPG')\ndef norm(x):\n  return (x - train_stats['mean']) / train_stats['std']\nnormed_train_data = norm(train_dataset)\nnormed_test_data = norm(test_dataset)\n\n\ndef build_model():\n  model = keras.Sequential([\n\n    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n    layers.Dense(64, activation='relu'),  # 'linear' instead of 'relu'\n    #layers.Dense(64, activation='relu'),\n    #layers.Dense(64, activation='relu'),\n    layers.Dense(1) ])\n\n  optimizer = tf.keras.optimizers.RMSprop(0.001)\n  model.compile(loss='mse',\n                optimizer=optimizer,\n                metrics=['mae', 'mse'])\n  return model\n\n\nmodel = build_model()\nmodel.summary()\n\nclass PrintDot(keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs):\n    if epoch % 100 == 0: print('')\n    print('.', end='')\n\nEPOCHS = 500\nhistory = model.fit(\n  normed_train_data, train_labels,\n  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n  callbacks=[PrintDot()])\n\nModel: \"sequential_15\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_53 (Dense)            (None, 64)                640       \n                                                                 \n dense_54 (Dense)            (None, 64)                4160      \n                                                                 \n dense_55 (Dense)            (None, 64)                4160      \n                                                                 \n dense_56 (Dense)            (None, 64)                4160      \n                                                                 \n dense_57 (Dense)            (None, 1)                 65        \n                                                                 \n=================================================================\nTotal params: 13185 (51.50 KB)\nTrainable params: 13185 (51.50 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n....................................................................................................\n....................................................................................................\n....................................................................................................\n....................................................................................................\n....................................................................................................\n\n\n\ndef plot_history(history):\n  hist = pd.DataFrame(history.history)\n  hist['epoch'] = history.epoch\n\n  plt.figure(figsize=(8,12))\n\n  plt.subplot(2,1,1)\n  plt.xlabel('Epoch')\n  plt.ylabel('Mean Abs Error [MPG]')\n  plt.plot(hist['epoch'], hist['mae'],\n           label='Train Error')\n  plt.plot(hist['epoch'], hist['val_mae'],\n           label = 'Val Error')\n  plt.ylim([0,5])\n  plt.legend()\n\n  plt.subplot(2,1,2)\n  plt.xlabel('Epoch')\n  plt.ylabel('Mean Square Error [$MPG^2$]')\n  plt.plot(hist['epoch'], hist['mse'],\n           label='Train Error')\n  plt.plot(hist['epoch'], hist['val_mse'],\n           label = 'Val Error')\n  plt.ylim([0,20])\n  plt.legend()\n  plt.show()\n\nplot_history(history)\n\n\n\n\n\ntest_predictions = model.predict(normed_test_data).flatten()\nyy = np.array(test_predictions)\nxx = np.array(normed_test_data[\"Weight\"])\nprint('MSE', np.mean(yy-test_labels)**2)\n\nidx = np.array(np.argsort(xx), dtype='int')\nprint(idx)\nxx = xx[idx]\nyy = yy[idx]\n\n3/3 [==============================] - 0s 4ms/step\nMSE 3.2270409256119708\n[ 9 65 44 56 38 24 76 57 74 66 43 45 40 37 67 60 10 52 41 21 13 30 68  3\n 50 75 34 61 11 64 73 25 27 49 72 77  4 62 23 63 59 22 33 31 18 47 36  8\n 51 46 48 32 29 69 58 70 28 39 71 16 26  0 55 53 15 54 42 12 14  6 35 20\n 17  5 19  1  2  7]\n\n\n\nplt.scatter(xx,yy)\nplt.show()"
  },
  {
    "objectID": "posts/VAE.html",
    "href": "posts/VAE.html",
    "title": "[DL] VAE",
    "section": "",
    "text": "!pip install torcheval\n\nimport torch\nimport numpy as np\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom torchvision.datasets import MNIST\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as transforms\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom torchvision.utils import save_image, make_grid\n\nis_cuda = torch.cuda.is_available()\nprint(is_cuda)\ndevice = torch.device('cuda' if is_cuda else 'cpu')\nprint('Current cuda device is', device)\n\nCollecting torcheval\n  Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 179.2/179.2 kB 3.7 MB/s eta 0:00:00 0:00:01\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.5.0)\nInstalling collected packages: torcheval\nSuccessfully installed torcheval-0.0.7\nTrue\nCurrent cuda device is cuda\n\n\n\n!nvcc --version\nprint(\"Torch version:{}\".format(torch.__version__))\nprint(\"cuda version: {}\".format(torch.version.cuda))\nprint(\"cudnn version:{}\".format(torch.backends.cudnn.version()))\n\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2022 NVIDIA Corporation\nBuilt on Wed_Sep_21_10:33:58_PDT_2022\nCuda compilation tools, release 11.8, V11.8.89\nBuild cuda_11.8.r11.8/compiler.31833905_0\nTorch version:2.1.0+cu118\ncuda version: 11.8\ncudnn version:8700\n\n\n\ntransform = transforms.Compose([transforms.ToTensor()])\n\n# download the MNIST datasets\npath = '~/datasets'\ntrain_dataset = MNIST(path, transform=transform, download=True)\ntest_dataset  = MNIST(path, transform=transform, download=True)\n\n# create train and test dataloaders\nbatch_size = 100\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/datasets/MNIST/raw/train-images-idx3-ubyte.gz\nExtracting /root/datasets/MNIST/raw/train-images-idx3-ubyte.gz to /root/datasets/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/datasets/MNIST/raw/train-labels-idx1-ubyte.gz\nExtracting /root/datasets/MNIST/raw/train-labels-idx1-ubyte.gz to /root/datasets/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\nExtracting /root/datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to /root/datasets/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\nExtracting /root/datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to /root/datasets/MNIST/raw\n\n\n\n100%|██████████| 9912422/9912422 [00:00&lt;00:00, 136550644.38it/s]\n100%|██████████| 28881/28881 [00:00&lt;00:00, 119936330.52it/s]\n100%|██████████| 1648877/1648877 [00:00&lt;00:00, 204267696.39it/s]\n100%|██████████| 4542/4542 [00:00&lt;00:00, 2259849.20it/s]\n\n\n\nimage = next(iter(train_loader))\n\nnum_samples = 25\nsample_images = [image[0][i+1,0] for i in range(num_samples)]\n\nfig = plt.figure(figsize=(5, 5))\ngrid = ImageGrid(fig, 111, nrows_ncols=(5, 5), axes_pad=0.1)\n\nfor ax, im in zip(grid, sample_images):\n    ax.imshow(im, cmap='gray')\n    ax.axis('off')\n\nplt.show()\n\n\n\n\n\nclass VAE(nn.Module):\n\n    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=200, device=device):\n        super(VAE, self).__init__()\n\n        # encoder\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.LeakyReLU(0.2),\n            nn.Linear(hidden_dim, latent_dim),\n            nn.LeakyReLU(0.2)\n            )\n\n        # latent mean and variance\n        self.mean_layer = nn.Linear(latent_dim, 2)\n        self.logvar_layer = nn.Linear(latent_dim, 2)\n\n        # decoder\n        self.decoder = nn.Sequential(\n            nn.Linear(2, latent_dim),\n            nn.LeakyReLU(0.2),\n            nn.Linear(latent_dim, hidden_dim),\n            nn.LeakyReLU(0.2),\n            nn.Linear(hidden_dim, input_dim),\n            nn.Sigmoid()\n            )\n\n    def encode(self, x):\n        x = self.encoder(x)\n        mean, logvar = self.mean_layer(x), self.logvar_layer(x)\n        return mean, logvar\n\n    def reparameterization(self, mean, var):\n        epsilon = torch.randn_like(var).to(device)\n        z = mean + var*epsilon\n        return z\n\n    def decode(self, x):\n        return self.decoder(x)\n\n    def forward(self, x):\n        mean, log_var = self.encode(x)\n        z = self.reparameterization(mean, log_var)\n        x_hat = self.decode(z)\n        return x_hat, mean, log_var\n\n\nmodel = VAE().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\ndef loss_function(x, x_hat, mean, log_var):\n    reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n    KLD = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n\n    return reproduction_loss + KLD\n\n\nx_dim = 784\n\ndef train(model, optimizer, epochs, device):\n    model.train()\n    for epoch in range(epochs):\n        overall_loss = 0\n        for batch_idx, (x, _) in enumerate(train_loader):\n            x = x.view(batch_size, x_dim).to(device)\n\n            optimizer.zero_grad()\n\n            x_hat, mean, log_var = model(x)\n            loss = loss_function(x, x_hat, mean, log_var)\n\n            overall_loss += loss.item()\n\n            loss.backward()\n            optimizer.step()\n\n        print(\"\\tEpoch\", epoch + 1, \"\\tAverage Loss: \", overall_loss/(batch_idx*batch_size))\n    return overall_loss\n\ntrain(model, optimizer, epochs=50, device=device)\n\n    Epoch 1     Average Loss:  175.29515954324916\n    Epoch 2     Average Loss:  157.1823385981845\n    Epoch 3     Average Loss:  152.55317100766902\n    Epoch 4     Average Loss:  149.62154792492697\n    Epoch 5     Average Loss:  147.50248990831074\n    Epoch 6     Average Loss:  145.86534660632304\n    Epoch 7     Average Loss:  144.4231314560726\n    Epoch 8     Average Loss:  143.31780508203778\n    Epoch 9     Average Loss:  142.30168281771702\n    Epoch 10    Average Loss:  141.49097752438962\n    Epoch 11    Average Loss:  140.83598308378546\n    Epoch 12    Average Loss:  140.17502820455968\n    Epoch 13    Average Loss:  139.8000655063126\n    Epoch 14    Average Loss:  139.30528065982367\n    Epoch 15    Average Loss:  138.87654218619573\n    Epoch 16    Average Loss:  138.48964087280885\n    Epoch 17    Average Loss:  138.1048076383817\n    Epoch 18    Average Loss:  137.74657612948664\n    Epoch 19    Average Loss:  137.45947488979027\n    Epoch 20    Average Loss:  137.23071929778797\n    Epoch 21    Average Loss:  136.92694877204195\n    Epoch 22    Average Loss:  136.66642131416944\n    Epoch 23    Average Loss:  136.39156210872287\n    Epoch 24    Average Loss:  136.2546355905676\n    Epoch 25    Average Loss:  136.01997696355906\n    Epoch 26    Average Loss:  135.8481364611592\n    Epoch 27    Average Loss:  135.6641933985027\n    Epoch 28    Average Loss:  135.42658317247495\n    Epoch 29    Average Loss:  135.3036438660789\n    Epoch 30    Average Loss:  135.2169284745409\n    Epoch 31    Average Loss:  134.92463263968594\n    Epoch 32    Average Loss:  134.92840655650042\n    Epoch 33    Average Loss:  134.6508390122861\n    Epoch 34    Average Loss:  134.68385046040277\n    Epoch 35    Average Loss:  134.47515039714628\n    Epoch 36    Average Loss:  134.2281339178579\n    Epoch 37    Average Loss:  134.29903941464943\n    Epoch 38    Average Loss:  134.0389246074186\n    Epoch 39    Average Loss:  133.95940814443344\n    Epoch 40    Average Loss:  133.74494802535474\n    Epoch 41    Average Loss:  133.6946707076899\n    Epoch 42    Average Loss:  133.62954862922578\n    Epoch 43    Average Loss:  133.38309982783807\n    Epoch 44    Average Loss:  133.46671858696786\n    Epoch 45    Average Loss:  133.28396186026188\n    Epoch 46    Average Loss:  133.149587479784\n    Epoch 47    Average Loss:  133.28342907123852\n    Epoch 48    Average Loss:  132.93941725792988\n    Epoch 49    Average Loss:  132.92503653550187\n    Epoch 50    Average Loss:  132.90003576925085\n\n\n7960712.142578125\n\n\n\ndef generate_digit(mean, var):\n    z_sample = torch.tensor([[mean, var]], dtype=torch.float).to(device)\n    print(z_sample)\n    x_decoded = model.decode(z_sample)\n    digit = x_decoded.detach().cpu().reshape(28, 28)  # reshape vector to 2d array\n    plt.imshow(digit, cmap='gray')\n    plt.axis('off')\n    plt.show()\n\ngenerate_digit(0.7,-1.0)\n\ntensor([[ 0.7000, -1.0000]], device='cuda:0')\n\n\n\n\n\n\ndef plot_latent_space(model, scale=1.0, n=25, digit_size=28, figsize=15):\n    # display a n*n 2D manifold of digits\n    figure = np.zeros((digit_size * n, digit_size * n))\n\n    # construct a grid\n    grid_x = np.linspace(-scale, scale, n)\n    grid_y = np.linspace(-scale, scale, n)[::-1]\n\n    for i, yi in enumerate(grid_y):\n        for j, xi in enumerate(grid_x):\n            z_sample = torch.tensor([[xi, yi]], dtype=torch.float).to(device)\n            x_decoded = model.decode(z_sample)\n            digit = x_decoded[0].detach().cpu().reshape(digit_size, digit_size)\n            figure[i * digit_size : (i + 1) * digit_size, j * digit_size : (j + 1) * digit_size,] = digit\n\n    plt.figure(figsize=(figsize, figsize))\n    plt.title('VAE Latent Space Visualization')\n    start_range = digit_size // 2\n    end_range = n * digit_size + start_range\n    pixel_range = np.arange(start_range, end_range, digit_size)\n    sample_range_x = np.round(grid_x, 1)\n    sample_range_y = np.round(grid_y, 1)\n    plt.xticks(pixel_range, sample_range_x)\n    plt.yticks(pixel_range, sample_range_y)\n    plt.xlabel(\"mean, z [0]\")\n    plt.ylabel(\"var, z [1]\")\n    plt.imshow(figure, cmap=\"Greys_r\")\n    plt.show()\n\nplot_latent_space(model)"
  },
  {
    "objectID": "posts/CV_CIFAR(1).html",
    "href": "posts/CV_CIFAR(1).html",
    "title": "[DL] CV_CIFAR(1)",
    "section": "",
    "text": "!pip install torcheval\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torcheval.metrics.functional import multiclass_f1_score\nfrom torchvision import datasets, transforms, models\nfrom matplotlib import pyplot as plt\nimport numpy as np\nfrom torchsummary import summary\n\nis_cuda = torch.cuda.is_available()\nprint(is_cuda)\ndevice = torch.device('cuda' if is_cuda else 'cpu')\nprint('Current cuda device is', device)\n\nRequirement already satisfied: torcheval in /usr/local/lib/python3.10/dist-packages (0.0.7)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.5.0)\nTrue\nCurrent cuda device is cuda\n\n\n\n!nvcc --version\nprint(\"Torch version:{}\".format(torch.__version__))\nprint(\"cuda version: {}\".format(torch.version.cuda))\nprint(\"cudnn version:{}\".format(torch.backends.cudnn.version()))\n\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2022 NVIDIA Corporation\nBuilt on Wed_Sep_21_10:33:58_PDT_2022\nCuda compilation tools, release 11.8, V11.8.89\nBuild cuda_11.8.r11.8/compiler.31833905_0\nTorch version:2.1.0+cu118\ncuda version: 11.8\ncudnn version:8700\n\n\n\ntrain_data = datasets.CIFAR10(root = './data/02/',\n                            train=True,\n                            download=True,\n                            transform=transforms.ToTensor())\n\ntest_data = datasets.CIFAR10(root = './data/02/',\n                            train=False,\n                            download=True,\n                            transform=transforms.ToTensor())\nprint('number of training data : ', len(train_data))\nprint('number of test data : ', len(test_data))\n\n# transform to normalize the data\ntransform = transforms.Compose([transforms.ToTensor(),\n                                transforms.Normalize((0.5,), (0.5,))])\n\n# Download and load the training data\ntrain_data = datasets.CIFAR10('./data', download=True, train=True,\n                              transform=transforms.Compose([transforms.Resize(224),transforms.ToTensor()])\n)\n# Download and load the test data\ntest_data = datasets.CIFAR10('./data', download=True, train=False,\n                              transform=transforms.Compose([transforms.Resize(224),transforms.ToTensor()])\n)\n\nprint('number of training data : ', len(train_data))\nprint('number of test data : ', len(test_data))\n\nFiles already downloaded and verified\nFiles already downloaded and verified\nnumber of training data :  50000\nnumber of test data :  10000\nFiles already downloaded and verified\nFiles already downloaded and verified\nnumber of training data :  50000\nnumber of test data :  10000\n\n\n\n원래는 32x32x3인데 224x224로 transforms 함수 써서 바꿈\n\n\nimage, label = train_data[10000]\nimage = image.permute(1, 2, 0)\nprint(image.shape)\n\nplt.figure()\nplt.imshow(image.numpy())\nplt.title('label : %s' % label)\nplt.show()\n\n#plt.imshow(image).squeeze().numpy(), cmap='rgb')\n#plt.show()\n\ntorch.Size([224, 224, 3])\n\n\n\n\n\n\nbatch_size = 100\ntrain_loader = torch.utils.data.DataLoader(dataset=train_data,\n                                           batch_size = batch_size, shuffle = True)\ntest_loader = torch.utils.data.DataLoader(dataset=test_data,\n                                           batch_size = batch_size, shuffle = True)\ntest_loaderA = torch.utils.data.DataLoader(dataset=test_data,\n                                           batch_size = batch_size, shuffle = True)\nfirst_batch = train_loader.__iter__().__next__()\n\n\nprint('{:15s} | {:&lt;25s} | {}'.format('name', 'type', 'size'))\nprint('{:15s} | {:&lt;25s} | {}'.format('Num of Batch', '', len(train_loader)))\nprint('{:15s} | {:&lt;25s} | {}'.format('first_batch', str(type(first_batch)), len(first_batch)))\nprint('{:15s} | {:&lt;25s} | {}'.format('first_batch[0]', str(type(first_batch[0])), first_batch[0].shape))\nprint('{:15s} | {:&lt;25s} | {}'.format('first_batch[1]', str(type(first_batch[1])), first_batch[1].shape))\n\nname            | type                      | size\nNum of Batch    |                           | 500\nfirst_batch     | &lt;class 'list'&gt;            | 2\nfirst_batch[0]  | &lt;class 'torch.Tensor'&gt;    | torch.Size([100, 3, 224, 224])\nfirst_batch[1]  | &lt;class 'torch.Tensor'&gt;    | torch.Size([100])\n\n\n\nresnet18_pretrained = models.resnet18(pretrained=True)\nresnet18_pretrained.to(\"cuda\")\n# summary(resnet18_pretrained, input_size=(3, 224, 224))\nfor param in resnet18_pretrained.parameters():\n    param.requires_grad = True  # Weights Freeze\n\nfor param in resnet18_pretrained.parameters():\n    param.requires_grad = True\n\nnum_ftrs = resnet18_pretrained.fc.in_features\nprint(num_ftrs) # ResNet18모델의 마지막 단에서, 출력 노드의 갯수를 구해주는 함수\nresnet18_pretrained.fc = nn.Linear(num_ftrs, 10)\nresnet18_pretrained.sf = nn.Softmax(dim=1)\nresnet18_pretrained = resnet18_pretrained.to(device)\n\n#print(resnet18_pretrained)\n\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n512\n\n\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, 3, 1, padding=(1,1))   #224*224   # (in-channe, out-channel,  , strinding)\n        self.conv2 = nn.Conv2d(16, 32, 3, 1, padding=(1,1))  #same\n        self.conv3 = nn.Conv2d(32, 100, 3, 1, padding=(1,1)) #same\n        self.dropout = nn.Dropout2d(0.25)\n        # (입력 뉴런, 출력 뉴런)\n        self.fc1 = nn.Linear(313600, 1000)    # 56*56*100 = 313600\n        self.fc2 = nn.Linear(1000, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)  # 반절 줄어\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)  # 반절 줄어\n        x = self.conv3(x)\n        x = F.relu(x)\n        x = self.dropout(x)\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n        output = F.log_softmax(x, dim=1)\n        return output\n\n\nmodel = CNN().to(device)\n#print(model)\n\nlearning_rate = 0.001\noptimizer = optim.Adam(resnet18_pretrained.parameters(), lr = learning_rate)\noptimizer0 = optim.Adam(model.parameters(), lr = learning_rate)\ncriterion = nn.CrossEntropyLoss()\n\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n위에를 통틀어서 convolution이라고 하기도 함\n\nresnet18_pretrained.train()\n#model.train()\n\nepoch_num = 2\ni = 1\nfor epoch in range(epoch_num):\n    for data, target in train_loader:\n        data = data.to(device)\n        target = target.to(device)\n        optimizer.zero_grad()\n        output = resnet18_pretrained(data)\n        #output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        if i % 100 == 0:\n            print(\"Train Step :{}  {}\\tLoss : {:3f}\".format(epoch, i, loss.item()))\n        i += 1\n\nTrain Step :0  100  Loss : 0.631524\nTrain Step :0  200  Loss : 0.641870\nTrain Step :0  300  Loss : 0.540941\nTrain Step :0  400  Loss : 0.372230\nTrain Step :0  500  Loss : 0.451633\nTrain Step :1  600  Loss : 0.276236\nTrain Step :1  700  Loss : 0.277767\nTrain Step :1  800  Loss : 0.369319\nTrain Step :1  900  Loss : 0.365539\nTrain Step :1  1000 Loss : 0.372553\n\n\n\nloss값이 strictly하게 감소는 안하지만.. 경양??적으로 감소함 (왔다 갔다 하면서 감소)\n\n\n\nresnet18_pretrained.eval()\ncorrect = 0\n\nfor data, target in test_loader:\n    data = data.to(device)\n    target = target.to(device)\n    output = resnet18_pretrained(data)\n    prediction = output.data.max(1)[1]\n    correct += prediction.eq(target.data).sum()\n\nprint('Test set Accuracy : {:.2f}%'.format(100. * correct / len(test_loader.dataset)))\n\nf1 = 0\nip = 0\nresnet18_pretrained.eval()\nfor data, target in test_loader:\n    data = data.to(device)\n    target = target.to(device)\n    output = resnet18_pretrained(data)\n    prediction = output.data.max(1)[1]\n    ip += 1\n    f1 += multiclass_f1_score(prediction, target, num_classes=10, average='micro')\n\nprint(f1/ip)\n\ntensor(0.8919, device='cuda:0')"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Boram-coco",
    "section": "",
    "text": "Everyday with Coco"
  }
]